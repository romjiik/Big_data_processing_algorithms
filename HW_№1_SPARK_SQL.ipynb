{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romjiik/Big_data_processing_algorithms/blob/main/HW_%E2%84%961_SPARK_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC9u5jdnHx50"
      },
      "source": [
        "# Домашнее задание № 1 (Apache Spark SQL)\n",
        "\n",
        "**Цель**: Решить 5 задач на SQL с использованием базовых таблиц.\n",
        "\n",
        "**Инструкции**:\n",
        "0. Прочитать условия ДЗ\n",
        "1. Выполнить задание на SQL;\n",
        "2. Ознакомиться с документацией по SQL: [Ссылка](https://spark.apache.org/docs/latest/sql-ref.html);\n",
        "3. Создать ноутбук с решениями задач (создайте копию на основе этого шаблона);\n",
        "4. Каждый запрос должен содержать обязательные комментарии с объяснением логического смысла решения;\n",
        "5. Скачать ноутбук в формате .ipynb и отправить на адрес электронной почты: ilya+hse@aniskovets.com.\n",
        "\n",
        "**Оценка и дедлайн**:\n",
        "- Максимальная оценка - 5 баллов;\n",
        "- Дедлайн: 24.05.2023 23:59;\n",
        "- Оценки будут опубликованы после сдачи **всех двух** домашних заданий.\n",
        "\n",
        "**Таблицы**:\n",
        "Для выполнения задания предполагается использование следующих таблиц, загруженных в систему в формате CSV с типами полей STRING:\n",
        "\n",
        "- title_basics_csv\n",
        "- title_principals_csv\n",
        "- title_crew_csv\n",
        "- title_episode_csv\n",
        "- title_ratings_csv\n",
        "- title_akas_csv\n",
        "- name_basics_csv\n",
        "\n",
        "**Преобразование типов**:\n",
        "Для преобразования STRING в другой тип используйте конструкцию: \n",
        "```sql\n",
        "CAST (column_name AS TYPE) AS column_name\n",
        "```\n",
        "\n",
        "**Пример**\n",
        "```sql\n",
        "CREATE TABLE test_table USING PARQUET AS \n",
        "  SELECT \n",
        "    CAST(averageRating AS decimal(2,1))  AS averageRating \n",
        "  FROM test_table_csv \n",
        "```\n",
        "\n",
        "**Все подготовительные этапы по преобразованию типов нужно делать в разделе Initialization. После чего, рекомендуется использовать в запросах таблицы в формате PARQUET**\n",
        "\n",
        "Перед этим не мешает проверить, что значения влезают в размерности этого типа\n",
        "Список типов SQL: https://spark.apache.org/docs/latest/sql-ref-datatypes.html \n",
        "\n",
        "Домашнее задание необходимо сделать в виде ноутбука. Ноутбук должен запускаться без ошибок.\n",
        "\n",
        "Во всех задачах ответом должно быть только ОДНО значение (число или строка).\n",
        "\n",
        "Неправильный ответ - 0 баллов за задачу.\n",
        "Правильный ответ на все тесты 1 балл за задачу, иначе пропорционально количеству пройденных тестов (количество тестов и какие именно заранее неизвестны).\n",
        "\n",
        "**ВНИМАНИЕ! К каждому запросу необходимо писать комментарии. Комментарии должны обьяснять логический смысл решения. Отсутствие комментария к решению задачи штраф - оценка за задачу = оценка / 2!**\n",
        "\n",
        "Всего 5 задач и 5 баллов\n",
        "\n",
        "**В режиме проверки SQL запросы будут запускаться с любыми параметрами, отличными от тех, что вы выбрали.**\n",
        "\n",
        "Скрипты не должны зависеть от выбранного вами параметра, а также от регистра строки. Все параметры должны быть изменяемыми (смотрите, пример в Вопросе № 0)\n",
        "\n",
        "**Тестирование будет проводится с любым значением параметров, в том числе с отсутвующим в датасете, запрос должен выводить правильный результат!**\n",
        "\n",
        "SQL запрос в ответе всегда должен быть один и параметризирован. Если необходимо пользуйтесь конструкцией WITH name AS () -  пример ниже\n",
        "\n",
        "После завершения работы нажимайте в меню File/Download/Download ipnb, скачивайте файл и присылайте почтой на ilya+hse@aniskovets.com\n",
        "\n",
        "Если заметили опечатки или появились вопросы пишите в телеграм: @aigmx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW6H3k8n0tYc",
        "outputId": "59591683-b6c4-4810-998e-e4d984360669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark===3.4.0\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark===3.4.0) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=3bc911c94e071923a7d77193238d9ec448a57b28f739e1062fc1cf2051c21be7\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark===3.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp42uQGB3Nez",
        "outputId": "998a41c5-cca2-47e9-ceaa-1537b00f036e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  132M  100  132M    0     0  12.5M      0  0:00:10  0:00:10 --:--:-- 17.0M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 51.7M  100 51.7M    0     0  8526k      0  0:00:06  0:00:06 --:--:-- 10.9M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 29.6M  100 29.6M    0     0  6673k      0  0:00:04  0:00:04 --:--:-- 7179k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  342M  100  342M    0     0  14.8M      0  0:00:23  0:00:23 --:--:-- 16.9M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 5526k  100 5526k    0     0  1604k      0  0:00:03  0:00:03 --:--:-- 1603k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  214M  100  214M    0     0  13.9M      0  0:00:15  0:00:15 --:--:-- 16.5M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  202M  100  202M    0     0  13.8M      0  0:00:14  0:00:14 --:--:-- 17.0M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://mars.ru77.ru/data/title.basics.tsv.gz\n",
        "!curl -O https://mars.ru77.ru/data/title.crew.tsv.gz\n",
        "!curl -O https://mars.ru77.ru/data/title.episode.tsv.gz\n",
        "!curl -O https://mars.ru77.ru/data/title.principals.tsv.gz\n",
        "!curl -O https://mars.ru77.ru/data/title.ratings.tsv.gz\n",
        "!curl -O https://mars.ru77.ru/data/title.akas.tsv.gz\n",
        "!curl -O https://mars.ru77.ru/data/name.basics.tsv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozFaxBjr3Lk8"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession, SQLContext\n",
        "from pyspark import SparkConf, SparkContext\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[2]\").config(\"spark.driver.memory\", \"8g\").appName(\"vse\").enableHiveSupport().getOrCreate()\n",
        "sql = spark.sql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1fn6BV_3KRJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "title_basics_csv = spark.read.csv(\"title.basics.tsv.gz\", sep='\\\\t', nullValue='\\\\N', header=True, quote=\"\", escape=\"\")\n",
        "title_basics_csv.createOrReplaceTempView(\"title_basics_csv\")\n",
        "\n",
        "\n",
        "title_principals_csv = spark.read.csv(\"title.principals.tsv.gz\", sep='\\\\t', nullValue='\\\\N', header=True, quote=\"\", escape=\"\")\n",
        "title_principals_csv.createOrReplaceTempView(\"title_principals_csv\")\n",
        "\n",
        "\n",
        "title_crew_csv = spark.read.csv(\"title.crew.tsv.gz\", sep='\\\\t', nullValue='\\\\N', header=True, quote=\"\", escape=\"\")\n",
        "title_crew_csv.createOrReplaceTempView(\"title_crew_csv\")\n",
        "\n",
        "\n",
        "title_episode_csv = spark.read.csv(\"title.episode.tsv.gz\", sep='\\\\t', nullValue='\\\\N', header=True, quote=\"\", escape=\"\")\n",
        "title_episode_csv.createOrReplaceTempView(\"title_episode_csv\")\n",
        "\n",
        "\n",
        "title_ratings_csv = spark.read.csv(\"title.ratings.tsv.gz\", sep='\\\\t', nullValue='\\\\N', header=True, quote=\"\", escape=\"\")\n",
        "title_ratings_csv.createOrReplaceTempView(\"title_ratings_csv\")\n",
        "\n",
        "\n",
        "title_akas_csv = spark.read.csv(\"title.akas.tsv.gz\", sep='\\\\t', nullValue='\\\\N', header=True, quote=\"\", escape=\"\")\n",
        "title_akas_csv.createOrReplaceTempView(\"title_akas_csv\")\n",
        "\n",
        "\n",
        "name_basics_csv = spark.read.csv(\"name.basics.tsv.gz\", sep='\\\\t', nullValue='\\\\N', header=True, quote=\"\", escape=\"\")\n",
        "name_basics_csv.createOrReplaceTempView(\"name_basics_csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1Oy8O6Fmjrn"
      },
      "outputs": [],
      "source": [
        "# Initialization\n",
        "_ = sql(\"\"\"DROP TABLE IF EXISTS title_basics\"\"\").collect()\n",
        "#преобразую числовые поля к нужному формату и выделю один жанр для каждой строки\n",
        "_ = sql(\"\"\"\n",
        "CREATE TABLE title_basics STORED AS PARQUET \n",
        "SELECT \n",
        "  tconst,\n",
        "  titleType,\n",
        "  primaryTitle,\n",
        "  originalTitle,\n",
        "  cast(isAdult as int) as isAdult,\n",
        "  cast(startYear as int) as startYear,\n",
        "  cast(endYear as int) as endYear,\n",
        "  cast(runtimeMinutes as int) as runtimeMinutes,\n",
        "  explode(split(genres, '[,]', -1)) as genre\n",
        "FROM title_basics_csv\"\"\").collect()\n",
        "\n",
        "_ = sql(\"\"\"DROP TABLE IF EXISTS title_principals\"\"\").collect()\n",
        "_ = sql(\"\"\"\n",
        "CREATE TABLE title_principals STORED AS PARQUET \n",
        "SELECT \n",
        "  tconst,\n",
        "  cast(ordering as int) as ordering,\n",
        "  nconst,\n",
        "  category,\n",
        "  job,\n",
        "  characters\n",
        "FROM title_principals_csv\"\"\").collect()\n",
        "\n",
        "_ = sql(\"\"\"DROP TABLE IF EXISTS title_crew\"\"\").collect()\n",
        "\n",
        "_ = sql(\"\"\"\n",
        "CREATE TABLE title_crew STORED AS PARQUET\n",
        " SELECT\n",
        "  tconst,\n",
        "  directors,\n",
        "  explode_outer(split(writers, '[,]', -1)) as writer\n",
        " FROM title_crew_csv\"\"\").collect()\n",
        "\n",
        "_ = sql(\"\"\"DROP TABLE IF EXISTS title_episode\"\"\").collect()\n",
        "_ = sql(\"\"\"\n",
        "CREATE TABLE title_episode STORED AS PARQUET \n",
        "SELECT \n",
        "  tconst,\n",
        "  parentTconst,\n",
        "  cast(seasonNumber as int) as seasonNumber,\n",
        "  cast(episodeNumber as int) as episodeNumber\n",
        "FROM title_episode_csv\"\"\").collect()\n",
        "\n",
        "_ = sql(\"\"\"DROP TABLE IF EXISTS title_ratings\"\"\").collect()\n",
        "_ = sql(\"\"\"\n",
        "CREATE TABLE title_ratings STORED AS PARQUET \n",
        "SELECT \n",
        "  tconst,\n",
        "  cast(averageRating as decimal(2,1)) as averageRating,\n",
        "  cast(numVotes as int) as numVotes                    \n",
        "FROM title_ratings_csv\"\"\").collect()\n",
        "                     \n",
        "_ = sql(\"\"\"DROP TABLE IF EXISTS title_akas\"\"\").collect()\n",
        "_ = sql(\"\"\"\n",
        "CREATE TABLE title_akas STORED AS PARQUET \n",
        "SELECT \n",
        "  titleId,\n",
        "  cast(ordering as decimal(2,1)) as ordering,\n",
        "  title,\n",
        "  region,\n",
        "  language,\n",
        "  types,\n",
        "  attributes,\n",
        "  cast(isOriginalTitle as int) as isOriginalTitle                \n",
        "FROM title_akas_csv\"\"\").collect()\n",
        "\n",
        "_ = sql(\"\"\"DROP TABLE IF EXISTS name_basics\"\"\").collect()\n",
        "_ = sql(\"\"\"\n",
        "CREATE TABLE name_basics STORED AS PARQUET \n",
        "SELECT \n",
        "  nconst,\n",
        "  primaryName,\n",
        "  cast(birthYear as int) as birthYear,\n",
        "  cast(deathYear as int) as deathYear,\n",
        "  primaryProfession,\n",
        "  knownForTitles              \n",
        "FROM name_basics_csv\"\"\").collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX4RUhILnx7m",
        "outputId": "32e1a67f-6e8e-4f3e-c839-9d1144120637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|col_name                    |data_type                                                     |comment|\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|tconst                      |string                                                        |null   |\n",
            "|titleType                   |string                                                        |null   |\n",
            "|primaryTitle                |string                                                        |null   |\n",
            "|originalTitle               |string                                                        |null   |\n",
            "|isAdult                     |int                                                           |null   |\n",
            "|startYear                   |int                                                           |null   |\n",
            "|endYear                     |int                                                           |null   |\n",
            "|runtimeMinutes              |int                                                           |null   |\n",
            "|genre                       |string                                                        |null   |\n",
            "|                            |                                                              |       |\n",
            "|# Detailed Table Information|                                                              |       |\n",
            "|Catalog                     |spark_catalog                                                 |       |\n",
            "|Database                    |default                                                       |       |\n",
            "|Table                       |title_basics                                                  |       |\n",
            "|Owner                       |root                                                          |       |\n",
            "|Created Time                |Sun May 21 20:01:27 UTC 2023                                  |       |\n",
            "|Last Access                 |UNKNOWN                                                       |       |\n",
            "|Created By                  |Spark 3.4.0                                                   |       |\n",
            "|Type                        |MANAGED                                                       |       |\n",
            "|Provider                    |hive                                                          |       |\n",
            "|Table Properties            |[transient_lastDdlTime=1684699287]                            |       |\n",
            "|Location                    |file:/content/spark-warehouse/title_basics                    |       |\n",
            "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe   |       |\n",
            "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat |       |\n",
            "|OutputFormat                |org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat|       |\n",
            "|Storage Properties          |[serialization.format=1]                                      |       |\n",
            "|Partition Provider          |Catalog                                                       |       |\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|col_name                    |data_type                                                     |comment|\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|tconst                      |string                                                        |null   |\n",
            "|ordering                    |int                                                           |null   |\n",
            "|nconst                      |string                                                        |null   |\n",
            "|category                    |string                                                        |null   |\n",
            "|job                         |string                                                        |null   |\n",
            "|characters                  |string                                                        |null   |\n",
            "|                            |                                                              |       |\n",
            "|# Detailed Table Information|                                                              |       |\n",
            "|Catalog                     |spark_catalog                                                 |       |\n",
            "|Database                    |default                                                       |       |\n",
            "|Table                       |title_principals                                              |       |\n",
            "|Owner                       |root                                                          |       |\n",
            "|Created Time                |Sun May 21 20:02:36 UTC 2023                                  |       |\n",
            "|Last Access                 |UNKNOWN                                                       |       |\n",
            "|Created By                  |Spark 3.4.0                                                   |       |\n",
            "|Type                        |MANAGED                                                       |       |\n",
            "|Provider                    |hive                                                          |       |\n",
            "|Table Properties            |[transient_lastDdlTime=1684699356]                            |       |\n",
            "|Location                    |file:/content/spark-warehouse/title_principals                |       |\n",
            "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe   |       |\n",
            "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat |       |\n",
            "|OutputFormat                |org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat|       |\n",
            "|Storage Properties          |[serialization.format=1]                                      |       |\n",
            "|Partition Provider          |Catalog                                                       |       |\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|col_name                    |data_type                                                     |comment|\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|tconst                      |string                                                        |null   |\n",
            "|directors                   |string                                                        |null   |\n",
            "|writer                      |string                                                        |null   |\n",
            "|                            |                                                              |       |\n",
            "|# Detailed Table Information|                                                              |       |\n",
            "|Catalog                     |spark_catalog                                                 |       |\n",
            "|Database                    |default                                                       |       |\n",
            "|Table                       |title_crew                                                    |       |\n",
            "|Owner                       |root                                                          |       |\n",
            "|Created Time                |Sun May 21 20:05:26 UTC 2023                                  |       |\n",
            "|Last Access                 |UNKNOWN                                                       |       |\n",
            "|Created By                  |Spark 3.4.0                                                   |       |\n",
            "|Type                        |MANAGED                                                       |       |\n",
            "|Provider                    |hive                                                          |       |\n",
            "|Table Properties            |[transient_lastDdlTime=1684699526]                            |       |\n",
            "|Location                    |file:/content/spark-warehouse/title_crew                      |       |\n",
            "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe   |       |\n",
            "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat |       |\n",
            "|OutputFormat                |org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat|       |\n",
            "|Storage Properties          |[serialization.format=1]                                      |       |\n",
            "|Partition Provider          |Catalog                                                       |       |\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|col_name                    |data_type                                                     |comment|\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|tconst                      |string                                                        |null   |\n",
            "|parentTconst                |string                                                        |null   |\n",
            "|seasonNumber                |int                                                           |null   |\n",
            "|episodeNumber               |int                                                           |null   |\n",
            "|                            |                                                              |       |\n",
            "|# Detailed Table Information|                                                              |       |\n",
            "|Catalog                     |spark_catalog                                                 |       |\n",
            "|Database                    |default                                                       |       |\n",
            "|Table                       |title_episode                                                 |       |\n",
            "|Owner                       |root                                                          |       |\n",
            "|Created Time                |Sun May 21 20:05:59 UTC 2023                                  |       |\n",
            "|Last Access                 |UNKNOWN                                                       |       |\n",
            "|Created By                  |Spark 3.4.0                                                   |       |\n",
            "|Type                        |MANAGED                                                       |       |\n",
            "|Provider                    |hive                                                          |       |\n",
            "|Table Properties            |[transient_lastDdlTime=1684699559]                            |       |\n",
            "|Location                    |file:/content/spark-warehouse/title_episode                   |       |\n",
            "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe   |       |\n",
            "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat |       |\n",
            "|OutputFormat                |org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat|       |\n",
            "|Storage Properties          |[serialization.format=1]                                      |       |\n",
            "|Partition Provider          |Catalog                                                       |       |\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|col_name                    |data_type                                                     |comment|\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|tconst                      |string                                                        |null   |\n",
            "|averageRating               |decimal(2,1)                                                  |null   |\n",
            "|numVotes                    |int                                                           |null   |\n",
            "|                            |                                                              |       |\n",
            "|# Detailed Table Information|                                                              |       |\n",
            "|Catalog                     |spark_catalog                                                 |       |\n",
            "|Database                    |default                                                       |       |\n",
            "|Table                       |title_ratings                                                 |       |\n",
            "|Owner                       |root                                                          |       |\n",
            "|Created Time                |Sun May 21 20:06:16 UTC 2023                                  |       |\n",
            "|Last Access                 |UNKNOWN                                                       |       |\n",
            "|Created By                  |Spark 3.4.0                                                   |       |\n",
            "|Type                        |MANAGED                                                       |       |\n",
            "|Provider                    |hive                                                          |       |\n",
            "|Table Properties            |[transient_lastDdlTime=1684699576]                            |       |\n",
            "|Location                    |file:/content/spark-warehouse/title_ratings                   |       |\n",
            "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe   |       |\n",
            "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat |       |\n",
            "|OutputFormat                |org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat|       |\n",
            "|Storage Properties          |[serialization.format=1]                                      |       |\n",
            "|Partition Provider          |Catalog                                                       |       |\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|col_name                    |data_type                                                     |comment|\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|titleId                     |string                                                        |null   |\n",
            "|ordering                    |decimal(2,1)                                                  |null   |\n",
            "|title                       |string                                                        |null   |\n",
            "|region                      |string                                                        |null   |\n",
            "|language                    |string                                                        |null   |\n",
            "|types                       |string                                                        |null   |\n",
            "|attributes                  |string                                                        |null   |\n",
            "|isOriginalTitle             |int                                                           |null   |\n",
            "|                            |                                                              |       |\n",
            "|# Detailed Table Information|                                                              |       |\n",
            "|Catalog                     |spark_catalog                                                 |       |\n",
            "|Database                    |default                                                       |       |\n",
            "|Table                       |title_akas                                                    |       |\n",
            "|Owner                       |root                                                          |       |\n",
            "|Created Time                |Sun May 21 20:06:20 UTC 2023                                  |       |\n",
            "|Last Access                 |UNKNOWN                                                       |       |\n",
            "|Created By                  |Spark 3.4.0                                                   |       |\n",
            "|Type                        |MANAGED                                                       |       |\n",
            "|Provider                    |hive                                                          |       |\n",
            "|Table Properties            |[transient_lastDdlTime=1684699580]                            |       |\n",
            "|Location                    |file:/content/spark-warehouse/title_akas                      |       |\n",
            "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe   |       |\n",
            "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat |       |\n",
            "|OutputFormat                |org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat|       |\n",
            "|Storage Properties          |[serialization.format=1]                                      |       |\n",
            "|Partition Provider          |Catalog                                                       |       |\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|col_name                    |data_type                                                     |comment|\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|nconst                      |string                                                        |null   |\n",
            "|primaryName                 |string                                                        |null   |\n",
            "|birthYear                   |int                                                           |null   |\n",
            "|deathYear                   |int                                                           |null   |\n",
            "|primaryProfession           |string                                                        |null   |\n",
            "|knownForTitles              |string                                                        |null   |\n",
            "|                            |                                                              |       |\n",
            "|# Detailed Table Information|                                                              |       |\n",
            "|Catalog                     |spark_catalog                                                 |       |\n",
            "|Database                    |default                                                       |       |\n",
            "|Table                       |name_basics                                                   |       |\n",
            "|Owner                       |root                                                          |       |\n",
            "|Created Time                |Sun May 21 20:08:27 UTC 2023                                  |       |\n",
            "|Last Access                 |UNKNOWN                                                       |       |\n",
            "|Created By                  |Spark 3.4.0                                                   |       |\n",
            "|Type                        |MANAGED                                                       |       |\n",
            "|Provider                    |hive                                                          |       |\n",
            "|Table Properties            |[transient_lastDdlTime=1684699707]                            |       |\n",
            "|Location                    |file:/content/spark-warehouse/name_basics                     |       |\n",
            "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe   |       |\n",
            "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat |       |\n",
            "|OutputFormat                |org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat|       |\n",
            "|Storage Properties          |[serialization.format=1]                                      |       |\n",
            "|Partition Provider          |Catalog                                                       |       |\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sql(\"DESCRIBE FORMATTED title_basics\").show(50, truncate=False)\n",
        "sql(\"DESCRIBE FORMATTED title_principals\").show(50, truncate=False)\n",
        "sql(\"DESCRIBE FORMATTED title_crew\").show(50, truncate=False)\n",
        "sql(\"DESCRIBE FORMATTED title_episode\").show(50, truncate=False)\n",
        "sql(\"DESCRIBE FORMATTED title_ratings\").show(50, truncate=False)\n",
        "sql(\"DESCRIBE FORMATTED title_akas\").show(50, truncate=False)\n",
        "sql(\"DESCRIBE FORMATTED name_basics\").show(50, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHfHxnjJ2a_e"
      },
      "source": [
        "Вопрос №0 (не оценивается, показан, как пример). Сколько произведений имеют средний рейтинг выше заданного {threshold}?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WurxaxmJJ3NY",
        "outputId": "1b64511e-416e-4e3d-e3bf-c99bf2b5a993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+----------------------+----------------------+-------+---------+-------+--------------+-----------+\n",
            "|tconst   |titleType|primaryTitle          |originalTitle         |isAdult|startYear|endYear|runtimeMinutes|genre      |\n",
            "+---------+---------+----------------------+----------------------+-------+---------+-------+--------------+-----------+\n",
            "|tt0000001|short    |Carmencita            |Carmencita            |0      |1894     |null   |1             |Documentary|\n",
            "|tt0000001|short    |Carmencita            |Carmencita            |0      |1894     |null   |1             |Short      |\n",
            "|tt0000002|short    |Le clown et ses chiens|Le clown et ses chiens|0      |1892     |null   |5             |Animation  |\n",
            "|tt0000002|short    |Le clown et ses chiens|Le clown et ses chiens|0      |1892     |null   |5             |Short      |\n",
            "|tt0000003|short    |Pauvre Pierrot        |Pauvre Pierrot        |0      |1892     |null   |4             |Animation  |\n",
            "|tt0000003|short    |Pauvre Pierrot        |Pauvre Pierrot        |0      |1892     |null   |4             |Comedy     |\n",
            "|tt0000003|short    |Pauvre Pierrot        |Pauvre Pierrot        |0      |1892     |null   |4             |Romance    |\n",
            "|tt0000004|short    |Un bon bock           |Un bon bock           |0      |1892     |null   |12            |Animation  |\n",
            "|tt0000004|short    |Un bon bock           |Un bon bock           |0      |1892     |null   |12            |Short      |\n",
            "|tt0000005|short    |Blacksmith Scene      |Blacksmith Scene      |0      |1893     |null   |1             |Comedy     |\n",
            "+---------+---------+----------------------+----------------------+-------+---------+-------+--------------+-----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+---------+--------+---------+---------------+-----------------------+----------+\n",
            "|tconst   |ordering|nconst   |category       |job                    |characters|\n",
            "+---------+--------+---------+---------------+-----------------------+----------+\n",
            "|tt0000001|1       |nm1588970|self           |null                   |[\"Self\"]  |\n",
            "|tt0000001|2       |nm0005690|director       |null                   |null      |\n",
            "|tt0000001|3       |nm0374658|cinematographer|director of photography|null      |\n",
            "|tt0000002|1       |nm0721526|director       |null                   |null      |\n",
            "|tt0000002|2       |nm1335271|composer       |null                   |null      |\n",
            "|tt0000003|1       |nm0721526|director       |null                   |null      |\n",
            "|tt0000003|2       |nm1770680|producer       |producer               |null      |\n",
            "|tt0000003|3       |nm1335271|composer       |null                   |null      |\n",
            "|tt0000003|4       |nm5442200|editor         |null                   |null      |\n",
            "|tt0000004|1       |nm0721526|director       |null                   |null      |\n",
            "+---------+--------+---------+---------------+-----------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+---------+-------------------+---------+\n",
            "|tconst   |directors          |writer   |\n",
            "+---------+-------------------+---------+\n",
            "|tt0000001|nm0005690          |null     |\n",
            "|tt0000002|nm0721526          |null     |\n",
            "|tt0000003|nm0721526          |null     |\n",
            "|tt0000004|nm0721526          |null     |\n",
            "|tt0000005|nm0005690          |null     |\n",
            "|tt0000006|nm0005690          |null     |\n",
            "|tt0000007|nm0005690,nm0374658|null     |\n",
            "|tt0000008|nm0005690          |null     |\n",
            "|tt0000009|nm0085156          |nm0085156|\n",
            "|tt0000010|nm0525910          |null     |\n",
            "+---------+-------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+---------+------------+------------+-------------+\n",
            "|tconst   |parentTconst|seasonNumber|episodeNumber|\n",
            "+---------+------------+------------+-------------+\n",
            "|tt0041951|tt0041038   |1           |9            |\n",
            "|tt0042816|tt0989125   |1           |17           |\n",
            "|tt0042889|tt0989125   |null        |null         |\n",
            "|tt0043426|tt0040051   |3           |42           |\n",
            "|tt0043631|tt0989125   |2           |16           |\n",
            "|tt0043693|tt0989125   |2           |8            |\n",
            "|tt0043710|tt0989125   |3           |3            |\n",
            "|tt0044093|tt0959862   |1           |6            |\n",
            "|tt0044668|tt0044243   |2           |16           |\n",
            "|tt0044901|tt0989125   |3           |46           |\n",
            "+---------+------------+------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+---------+-------------+--------+\n",
            "|tconst   |averageRating|numVotes|\n",
            "+---------+-------------+--------+\n",
            "|tt0000001|5.7          |1697    |\n",
            "|tt0000002|6.0          |211     |\n",
            "|tt0000003|6.5          |1451    |\n",
            "|tt0000004|6.1          |123     |\n",
            "|tt0000005|6.1          |2248    |\n",
            "|tt0000006|5.2          |125     |\n",
            "|tt0000007|5.4          |687     |\n",
            "|tt0000008|5.4          |1874    |\n",
            "|tt0000009|6.0          |155     |\n",
            "|tt0000010|6.9          |6296    |\n",
            "+---------+-------------+--------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+---------+--------+-------------------------+------+--------+-----------+-------------+---------------+\n",
            "|titleId  |ordering|title                    |region|language|types      |attributes   |isOriginalTitle|\n",
            "+---------+--------+-------------------------+------+--------+-----------+-------------+---------------+\n",
            "|tt0000001|1.0     |Карменсіта               |UA    |null    |imdbDisplay|null         |0              |\n",
            "|tt0000001|2.0     |Carmencita               |DE    |null    |null       |literal title|0              |\n",
            "|tt0000001|3.0     |Carmencita - spanyol tánc|HU    |null    |imdbDisplay|null         |0              |\n",
            "|tt0000001|4.0     |Καρμενσίτα               |GR    |null    |imdbDisplay|null         |0              |\n",
            "|tt0000001|5.0     |Карменсита               |RU    |null    |imdbDisplay|null         |0              |\n",
            "|tt0000001|6.0     |Carmencita               |US    |null    |null       |null         |0              |\n",
            "|tt0000001|7.0     |Carmencita               |null  |null    |original   |null         |1              |\n",
            "|tt0000001|8.0     |カルメンチータ           |JP    |ja      |imdbDisplay|null         |0              |\n",
            "|tt0000002|1.0     |Le clown et ses chiens   |null  |null    |original   |null         |1              |\n",
            "|tt0000002|2.0     |A bohóc és kutyái        |HU    |null    |imdbDisplay|null         |0              |\n",
            "+---------+--------+-------------------------+------+--------+-----------+-------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+---------+---------------+---------+---------+-----------------------------------+---------------------------------------+\n",
            "|nconst   |primaryName    |birthYear|deathYear|primaryProfession                  |knownForTitles                         |\n",
            "+---------+---------------+---------+---------+-----------------------------------+---------------------------------------+\n",
            "|nm0000001|Fred Astaire   |1899     |1987     |soundtrack,actor,miscellaneous     |tt0031983,tt0072308,tt0050419,tt0053137|\n",
            "|nm0000002|Lauren Bacall  |1924     |2014     |actress,soundtrack                 |tt0117057,tt0071877,tt0038355,tt0037382|\n",
            "|nm0000003|Brigitte Bardot|1934     |null     |actress,soundtrack,music_department|tt0057345,tt0054452,tt0049189,tt0056404|\n",
            "|nm0000004|John Belushi   |1949     |1982     |actor,soundtrack,writer            |tt0072562,tt0080455,tt0078723,tt0077975|\n",
            "|nm0000005|Ingmar Bergman |1918     |2007     |writer,director,actor              |tt0050976,tt0050986,tt0069467,tt0060827|\n",
            "|nm0000006|Ingrid Bergman |1915     |1982     |actress,soundtrack,producer        |tt0038109,tt0077711,tt0036855,tt0034583|\n",
            "|nm0000007|Humphrey Bogart|1899     |1957     |actor,soundtrack,producer          |tt0043265,tt0042593,tt0034583,tt0033870|\n",
            "|nm0000008|Marlon Brando  |1924     |2004     |actor,soundtrack,director          |tt0078788,tt0070849,tt0068646,tt0047296|\n",
            "|nm0000009|Richard Burton |1925     |1984     |actor,soundtrack,producer          |tt0087803,tt0057877,tt0059749,tt0061184|\n",
            "|nm0000010|James Cagney   |1899     |1986     |actor,soundtrack,director          |tt0035575,tt0042041,tt0029870,tt0031867|\n",
            "+---------+---------------+---------+---------+-----------------------------------+---------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sql('''select * from title_basics''').show(10, truncate=False)\n",
        "sql('''select * from title_principals''').show(10, truncate=False)\n",
        "sql('''select * from title_crew''').show(10, truncate=False)\n",
        "sql('''select * from title_episode''').show(10, truncate=False)\n",
        "sql('''select * from title_ratings''').show(10, truncate=False)\n",
        "sql('''select * from title_akas''').show(10, truncate=False)\n",
        "sql('''select * from name_basics''').show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr2IF_C70sp3",
        "outputId": "5de3cab6-c414-4cc5-bb86-fe3a731157c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|cnt_above_threshold|\n",
            "+-------------------+\n",
            "|1025071            |\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query_0 = \"\"\"\n",
        "/*\n",
        "  Чтобы посчитать количество произведений находим все рейтинги больше, чем заданный порог.\n",
        "  Так как надо найти все произведения, а не только фильмы, нам не нужно делать фильтр по типу произведения titleType\n",
        "*/\n",
        "SELECT \n",
        "  COUNT(tconst) as cnt_above_threshold\n",
        "FROM  title_ratings\n",
        "WHERE averageRating > {threshold};\n",
        "\"\"\"\n",
        "sql(query_0, threshold=5.0).show(truncate=False)\n",
        "#1029097"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0Xdfa0T6ZUT"
      },
      "source": [
        "Вопрос №1. Найдите среднюю продолжительность (title_basics:runtimeMinutes) фильмов (title_basics:titleType=movie) определенного жанра {genre}. \n",
        "\n",
        "Среднюю продолжительность надо рассчитать только для тех фильмов, где title_basics:runtimeMinutes не равен NULL. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJJ_XspE6kP6",
        "outputId": "ee977eab-5daf-4ea5-911a-220a10e63699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|MeanRuntimeMinutes|\n",
            "+------------------+\n",
            "|96.39210319748258 |\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query_1 = \"\"\"\n",
        "/*\n",
        "  Чтобы посчитать среднее время, нужно использовать аггр функцию mean() с условиями, что тип - фильм, время - не null и определенный жанр\n",
        "*/\n",
        "select\n",
        "  mean(runtimeMinutes) as MeanRuntimeMinutes\n",
        "from \n",
        "  title_basics\n",
        "where 1 = 1\n",
        "  and titleType = 'movie'\n",
        "  and genre = {genre}\n",
        "  and runtimeMinutes is not null\n",
        "\"\"\"\n",
        "sql(query_1, genre='Drama').show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX4TaRQS4Mjb"
      },
      "source": [
        "Вопрос №2. Сколько фильмов (title_basics:titleType=movie) определенного жанра (title_basics:genres) {genre} было выпущено в определенный год (title_basics:startYear) {year}?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOMaygnv4Wce",
        "outputId": "770648a2-dec2-46cc-e9e3-d3c0850a2397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|CountFilms|\n",
            "+----------+\n",
            "|219       |\n",
            "+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query_2 = \"\"\"\n",
        "/*\n",
        "  считаем кол-во уникальных(потому что я сделал explode по жанру) идентификаторов с условиями на тип тайтла, жанр и год\n",
        "*/\n",
        "select\n",
        "  count(distinct tconst) as CountFilms\n",
        "from \n",
        "  title_basics\n",
        "where 1 = 1\n",
        "  and titleType = 'movie'\n",
        "  and genre = {genre}\n",
        "  and startYear = {year}\n",
        "\"\"\"\n",
        "sql(query_2, genre='Action', year=2022).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnAxHdo84q8n"
      },
      "source": [
        "Вопрос №3. Сколько фильмов определенного жанра (title_basics:genres) {genre}, в которых снялся конкретный актер (name_basics:primaryName) {actor}, имеют средний рейтинг (title_ratings:averageRating) выше заданного порога {threshold}?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBzpWjod5BsT",
        "outputId": "76653b3c-4c31-4746-f393-57804830ada7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+\n",
            "|count(1)|\n",
            "+--------+\n",
            "|0       |\n",
            "+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query_30 = \"\"\"\n",
        "/*\n",
        "  Это проверка, что нет потерь в данных. То есть айди тайтлов, которые есть в title_basics есть и в других используемых таблицах\n",
        "*/\n",
        "with pre as (\n",
        "select\n",
        "  case\n",
        "    when t2.tconst is null then 'noInfo'\n",
        "    else t2.tconst\n",
        "  end as tconst\n",
        "from\n",
        "  title_basics t1\n",
        "  left join title_ratings t2 \n",
        "    on t1.tconst = t2.tconst\n",
        "  left join title_principals t3\n",
        "    on t1.tconst = t3.tconst\n",
        "  left join name_basics t4\n",
        "    on t3.nconst = t4.nconst\n",
        "group by 1\n",
        ")\n",
        "select count(*) from pre where tconst is null\n",
        "\"\"\"\n",
        "sql(query_30).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIGShXTL-VJ-",
        "outputId": "13f67081-d057-4751-b92e-89eca1ce3014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|CountFilms|\n",
            "+----------+\n",
            "|20        |\n",
            "+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query_3 = \"\"\"\n",
        "/*\n",
        "  Чтобы узнать рейтинг надо к title_basics приджойнить таблицу title_ratings по условию равенста айди тайтла. Чтобы узнать имя актера надо к title_basics приджойнить title_principals по айди тайтла\n",
        "  и достать из этой таблицы айди актера, дальше по этому айди надо приджойнить таблицу name_basics и оттуда достать имя актера. Я проверил, что все тайтлы, которые есть в title_basics есть в title_principals,\n",
        "  поэтому потерь быть не должно. Также ставим фильтр на тип тайтла, так как по условию надо только фильмы\n",
        "*/\n",
        "select\n",
        "  count(distinct t1.tconst) as CountFilms\n",
        "from\n",
        "  title_basics t1\n",
        "  left join title_ratings t2 --достаю рейтинг\n",
        "    on t1.tconst = t2.tconst\n",
        "  left join title_principals t3 --достаю айди человека\n",
        "    on t1.tconst = t3.tconst\n",
        "  left join name_basics t4 --по айди человека нахожу его имя\n",
        "    on t3.nconst = t4.nconst\n",
        "where 1 = 1\n",
        "  and titleType = 'movie'\n",
        "  and t1.genre = {genre}\n",
        "  and t4.primaryName = {actor}\n",
        "  and t2.averageRating > {threshold} \n",
        "\"\"\"\n",
        "sql(query_3, genre='Comedy', actor='James Cagney', threshold=5.3).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pML6m5O42Hk"
      },
      "source": [
        "Вопрос №4. Сколько телесериалов (title_basics:titleType=tvSeries) в определенном жанре (title_basics:genres) {genre} имеют более определенного количества (title_episode:seasonNumber > {seasons})?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egSPXazk6mlr",
        "outputId": "4de71e0f-a643-41df-9132-cfe7a0b4ba49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|countSerials|\n",
            "+------------+\n",
            "|3546        |\n",
            "+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query_4 = \"\"\"\n",
        "/*\n",
        " К таблице title_basics джойню таблицу title_episode по айди тайтла(нужно заметить, что айди тайтла в этой таблице это parentTconst). Выбираю сериалы, определенного жанра и с определенным количество сезонов\n",
        "*/\n",
        "select\n",
        "  count(distinct t1.tconst) as countSerials\n",
        "from\n",
        "  title_basics t1\n",
        "  left join title_episode t2\n",
        "    on t1.tconst = t2.parentTconst\n",
        "where 1 = 1\n",
        "  and titleType = 'tvSeries'\n",
        "  and genre = {genre}\n",
        "  and seasonNumber > {seasons}\n",
        "\"\"\"\n",
        "sql(query_4, genre='Comedy', seasons=3).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c06R3Avo5jwH"
      },
      "source": [
        "Вопрос № 5. Сколько фильмов (title_basics:titleType=movie)  создал конкретный сценарист (title_crew:writers, name_basics:primaryName) {writer} в определенном жанре (title_basics:genres) {genre}?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu172vb05yKB",
        "outputId": "1ce51a54-3d82-4288-e197-67239f4b84b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+\n",
            "|count(DISTINCT tconst)|\n",
            "+----------------------+\n",
            "|38                    |\n",
            "+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query_5  = \"\"\"\n",
        "/*\n",
        "  Для начала к title_basics джойню таблицу title_crew. Оттуда я узнаю айди сценаристов. Дальше джойню таблицу name_basics по айди сценариста. И ставлю фильтр на имя сценариста и жанр. Также выбираю в title_basics\n",
        "  только фильмы\n",
        "*/\n",
        "select\n",
        "  count(distinct t1.tconst)\n",
        "from\n",
        "  title_basics t1\n",
        "  left join title_crew t2 --отсюда достаю айди сценриста\n",
        "    on t1.tconst = t2.tconst\n",
        "  left join name_basics t3 --отсюда достаю имя сценариста\n",
        "    on t2.writer = t3.nconst\n",
        "where 1 = 1\n",
        "  and titleType = 'movie'\n",
        "  and primaryName = {writer}\n",
        "  and genre = {genre}\n",
        "\"\"\"\n",
        "sql(query_5, genre='Drama', writer='Federico Fellini').show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmIJNzuVBqG5",
        "outputId": "f402944e-9efb-4b35-aa48-04125cb4c407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- answer 1\n",
            " \n",
            "/*\n",
            "  Чтобы посчитать среднее время, нужно использовать аггр функцию mean() с условиями, что тип - фильм, время - не null и определенный жанр\n",
            "*/\n",
            "select\n",
            "  mean(runtimeMinutes) as MeanRuntimeMinutes\n",
            "from \n",
            "  title_basics\n",
            "where 1 = 1\n",
            "  and titleType = 'movie'\n",
            "  and genre = {genre}\n",
            "  and runtimeMinutes is not null\n",
            ";\n",
            "\n",
            "-- answer 2\n",
            " \n",
            "/*\n",
            "  считаем кол-во уникальных(потому что я сделал explode по жанру) идентификаторов с условиями на тип тайтла, жанр и год\n",
            "*/\n",
            "select\n",
            "  count(distinct tconst) as CountFilms\n",
            "from \n",
            "  title_basics\n",
            "where 1 = 1\n",
            "  and titleType = 'movie'\n",
            "  and genre = {genre}\n",
            "  and startYear = {year}\n",
            ";\n",
            "\n",
            "-- answer 3\n",
            " \n",
            "/*\n",
            "  Чтобы узнать рейтинг надо к title_basics приджойнить таблицу title_ratings по условию равенста айди тайтла. Чтобы узнать имя актера надо к title_basics приджойнить title_principals по айди тайтла\n",
            "  и достать из этой таблицы айди актера, дальше по этому айди надо приджойнить таблицу name_basics и оттуда достать имя актера. Я проверил, что все тайтлы, которые есть в title_basics есть в title_principals,\n",
            "  поэтому потерь быть не должно. Также ставим фильтр на тип тайтла, так как по условию надо только фильмы\n",
            "*/\n",
            "select\n",
            "  count(distinct t1.tconst) as CountFilms\n",
            "from\n",
            "  title_basics t1\n",
            "  left join title_ratings t2 --достаю рейтинг\n",
            "    on t1.tconst = t2.tconst\n",
            "  left join title_principals t3 --достаю айди человека\n",
            "    on t1.tconst = t3.tconst\n",
            "  left join name_basics t4 --по айди человека нахожу его имя\n",
            "    on t3.nconst = t4.nconst\n",
            "where 1 = 1\n",
            "  and titleType = 'movie'\n",
            "  and t1.genre = {genre}\n",
            "  and t4.primaryName = {actor}\n",
            "  and t2.averageRating > {threshold} \n",
            ";\n",
            "\n",
            "-- answer 4\n",
            " \n",
            "/*\n",
            " К таблице title_basics джойню таблицу title_episode по айди тайтла(нужно заметить, что айди тайтла в этой таблице это parentTconst). Выбираю сериалы, определенного жанра и с определенным количество сезонов\n",
            "*/\n",
            "select\n",
            "  count(distinct t1.tconst) as countSerials\n",
            "from\n",
            "  title_basics t1\n",
            "  left join title_episode t2\n",
            "    on t1.tconst = t2.parentTconst\n",
            "where 1 = 1\n",
            "  and titleType = 'tvSeries'\n",
            "  and genre = {genre}\n",
            "  and seasonNumber > {seasons}\n",
            ";\n",
            "\n",
            "-- answer 5\n",
            " \n",
            "/*\n",
            "  Для начала к title_basics джойню таблицу title_crew. Оттуда я узнаю айди сценаристов. Дальше джойню таблицу name_basics по айди сценариста. И ставлю фильтр на имя сценариста и жанр. Также выбираю в title_basics\n",
            "  только фильмы\n",
            "*/\n",
            "select\n",
            "  count(distinct t1.tconst)\n",
            "from\n",
            "  title_basics t1\n",
            "  left join title_crew t2 --отсюда достаю айди сценриста\n",
            "    on t1.tconst = t2.tconst\n",
            "  left join name_basics t3 --отсюда достаю имя сценриста\n",
            "    on t2.writer = t3.nconst\n",
            "where 1 = 1\n",
            "  and titleType = 'movie'\n",
            "  and primaryName = {writer}\n",
            "  and genre = {genre}\n",
            ";\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# PLEASE DO NOT REMOVE THIS CELL\n",
        "\n",
        "# Generate answers\n",
        "for n in range(1, 6):\n",
        "  print(f\"-- answer {n}\\n \" + globals()[f\"query_{n}\"] + \";\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19RZWs_mkHyY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}